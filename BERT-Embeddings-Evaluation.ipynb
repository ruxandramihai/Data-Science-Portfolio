{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Embeddings with Fine-Tuned BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import pylab as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import metrics\n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import openai\n",
    "from datasets import Dataset\n",
    "import torch \n",
    "import os\n",
    "import ragas\n",
    "from ragas import evaluate\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/ruxandramihai/Desktop/RA/UK DRI Publications/embeddings.csv')\n",
    "#data['embeddings'] = data['embeddings'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings():\n",
    "    data = pd.read_csv('/Users/ruxandramihai/Desktop/embeddings.csv')\n",
    "    data['embeddings'] = data['embeddings'].apply(ast.literal_eval)\n",
    "    # drop cluster 1: all that have Erratum or Correction in Title\n",
    "    embeddings = np.vstack(data['embeddings'].values)\n",
    "    return data,embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /Users/ruxandramihai/Desktop/LLM/fine-tuned-pubmedBERT_5_epochs and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_config = AutoConfig.from_pretrained(\"/Users/ruxandramihai/Desktop/LLM/fine-tuned-pubmedBERT_5_epochs/config.json\")\n",
    "model = AutoModel.from_pretrained(\"/Users/ruxandramihai/Desktop/LLM/fine-tuned-pubmedBERT_5_epochs\", config = model_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/Users/ruxandramihai/Desktop/LLM/fine-tuned-pubmedBERT_5_epochs\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_embedding(query):\n",
    "    inputs = tokenizer(query, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    query_embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "    return query_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find similar documents \n",
    "def get_kclosest(query_embedding, k=5):\n",
    "    data, all_embeddings = load_embeddings()\n",
    "    if isinstance(query_embedding, torch.Tensor):\n",
    "        query_embedding = query_embedding.numpy()\n",
    "    if isinstance(all_embeddings, torch.Tensor):\n",
    "        all_embeddings = all_embeddings.numpy()\n",
    "    similarities = cosine_similarity(query_embedding, all_embeddings)\n",
    "    closest_indices = np.argsort(similarities[0])[-k:][::-1]\n",
    "    return data.iloc[closest_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 5000\n",
    "\n",
    "def get_context(query, k=5):\n",
    "    query_embedding = get_query_embedding(query)\n",
    "    closest_docs = get_kclosest(query_embedding, k)\n",
    "    contexts = [doc.Abstract for _, doc in closest_docs.iterrows()]\n",
    "    #dois = closest_docs.DOI.tolist()\n",
    "    #return dois, contexts\n",
    "    return contexts\n",
    "\n",
    "def retrieve(query,k=3):\n",
    "    dois ,contexts = get_context(query,k)\n",
    "\n",
    "    # build our prompt with the retrieved contexts included\n",
    "    prompt_start = (\n",
    "        \"Answer the question based on the context below.\\n\\n\"+\n",
    "        \"Context:\\n\"\n",
    "    )\n",
    "    prompt_end = (\n",
    "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    "    # append contexts until hitting limit\n",
    "    for i in range(1, len(contexts)):\n",
    "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= limit:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts[:i-1]) +\n",
    "                prompt_end\n",
    "            )\n",
    "            break\n",
    "        elif i == len(contexts)-1:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts) +\n",
    "                prompt_end\n",
    "            )\n",
    "    return prompt\n",
    "\n",
    "def response(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=150,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0)\n",
    "    return response.choices[0].message.content.replace(\"\\n\", \"\")\n",
    "\n",
    "def display(dois):\n",
    "    text = f\"\\n\\n Here are publications from UKDRI which are most relevant to your question: {', '.join(dois.values)}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check quality of answer and retrieved context - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/Users/ruxandramihai/Desktop/test_data_QnA_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doi,row in test_data.iterrows():\n",
    "    test_data.at[doi,'contexts'] = get_context(row.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(columns=['contexts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['10.1016/j.mcn.2018.12.004',\n",
       "  '10.1016/j.neurobiolaging.2022.04.009',\n",
       "  '10.1002/dad2.12167',\n",
       "  '10.1186/s13024-021-00430-x',\n",
       "  '10.2217/bmm-2017-0433'],\n",
       " [\"Alzheimer's disease (AD) is characterized by amyloid plaques and tau pathology (neurofibrillary tangles and neuropil threads). Amyloid plaques are primarily composed of aggregated and oligomeric β-amyloid (Aβ) peptides ending at position 42 (Aβ42). The development of fluid and PET biomarkers for Alzheimer's disease (AD), has allowed for detection of Aβ pathology in vivo and marks a major advancement in understanding the role of Aβ in Alzheimer's disease (AD). In the recent National Institute on Aging and Alzheimer's Association (NIA-AA) Research Framework, AD is defined by the underlying pathology as measured in patients during life by biomarkers (Jack et al., 2018), while clinical symptoms are used for staging of the disease. Therefore, sensitive, specific and robust biomarkers to identify brain amyloidosis are central in AD research. Here, we discuss fluid and PET biomarkers for Aβ and their application.\",\n",
       "  \"Studying the correlation between cerebrospinal fluid (CSF) metabolites and the Alzheimer's Disease (AD) biomarkers may offer a window to the alterations of the brain metabolome and unveil potential biological mechanisms underlying AD. In this analysis, 308 CSF metabolites from 338 individuals of Wisconsin Registry for Alzheimer's Prevention and Wisconsin Alzheimer's Disease Research Center were included in a principal component analysis (PCA). The resulted principal components (PCs) were tested for association with CSF total tau (t-tau), phosphorylated tau (p-tau), amyloid β 42 (Aβ42), and Aβ42/40 ratio using linear regression models. Significant PCs were further tested with other CSF NeuroToolKit (NTK) and imaging biomarkers. Using a Bonferroni corrected p < 0.05, 5 PCs were significantly associated with CSF p-tau and t-tau and 3 PCs were significantly associated with CSF Aβ42. Pathway analysis suggested that these PCS were enriched in 6 pathways, including metabolism of caffeine and nicotinate and nicotinamide. This study provides evidence that CSF metabolites are associated with AD pathology through core AD biomarkers and other NTK markers and suggests potential pathways to follow up in future studies.\",\n",
       "  \"INTRODUCTION: Cerebrospinal fluid (CSF) total tau (t-tau) and phosphorylated tau (p-tau) are biomarkers of Alzheimer's disease (AD), yet much is unknown about AD-associated changes in tau metabolism and tau tangle etiology.METHODS: We assessed the variation of t-tau and p-tau explained by 38 previously identified CSF metabolites using linear regression models in middle-age controls from the Wisconsin Alzheimer's Disease Research Center, and predicted AD/mild cognitive impairment (MCI) versus an independent set of older controls using metabolites selected by the least absolute shrinkage and selection operator (LASSO).RESULTS: The 38 CSF metabolites explained 70.3% and 75.7% of the variance in t-tau and p-tau, respectively. Of these, seven LASSO-selected metabolites improved the prediction ability of AD/MCI versus older controls (area under the curve score increased from 0.92 to 0.97 and 0.78 to 0.93) compared to the base model.DISCUSSION: These tau-correlated CSF metabolites increase AD/MCI prediction accuracy and may provide insight into tau tangle etiology.\",\n",
       "  \"Four fluid-based biomarkers have been developed into diagnostic tests for Alzheimer's disease (AD) pathology: the ratio of 42 to 40 amino acid-long amyloid β, a marker of plaque pathology; total-tau and phosphorylated tau, markers of AD-related changes in tau metabolism and secretion; and neurofilament light, a marker of neurodegeneration. When measured in cerebrospinal fluid, these biomarkers can be used in clinical practice to support a diagnosis of mild cognitive impairment or dementia due to AD. Recently, technological breakthroughs have made it possible to measure them in standard blood samples as well. Here, we give an updated account of the current state of the fluid-based AD biomarker research field. We discuss how the new blood tests may be used in research and clinical practice, and what role they may play in relation to more established diagnostic tests, such as CSF biomarkers and amyloid and tau positron emission tomography, to facilitate the effective implementation of future disease-modifying therapies.\",\n",
       "  \"At the center of Alzheimer's disease pathogenesis is the aberrant aggregation of amyloid-β (Aβ) into oligomers, fibrils and plaques. Effective monitoring of Aβ deposition directly in patients is essential to assist anti-Aβ therapeutics in target engagement and participant selection. In the advent of approved anti-Aβ therapeutics, biomarkers will become of fundamental importance in initiating treatments having disease modifying effects at the earliest stage. Two well-established Aβ biomarkers are widely utilized: Aβ-binding ligands for positron emission tomography and immunoassays to measure Aβ42 in cerebrospinal fluid. In this review, we will discuss the current clinical, diagnostic and research state of biomarkers for Aβ pathology. Furthermore, we will explore the current application of blood-based markers to assess Aβ pathology.\"])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.contexts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['ground_truth'] = test_data['ground_truths'].apply(lambda x: ' '.join(x))\n",
    "test_data['contexts'] = ''\n",
    "\n",
    "for doi,row in test_data.iterrows():\n",
    "    test_data.at[doi,'contexts'] = get_context(row.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20623ab925e84377bce8fd359563e342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16470b974e62455593f18e8fb1494a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6000bf29e6544a68796e4246d2d8384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12916ae7d5d547ba95c9e8bb47e877c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f71ae2a5ac04b80a523ad7d21de96c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aebcc2cc9a94471a8f1dd2c8c52789c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565f8f3f66734864a5763267625564d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220bc3e589c44e109bebed8dd394aead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f406b79d18e24c05a5d2d65323618ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "# split test_data into smaller chunks\n",
    "import time\n",
    "n=5\n",
    "delay_between_requests = 5\n",
    "chunks = [test_data[i:i + n] for i in range(0, len(test_data), n)]  # n is the size of each chunk\n",
    "\n",
    "results = []\n",
    "for c,chunk in enumerate(chunks[1:]):\n",
    "    print(c)\n",
    "    chunk = Dataset.from_dict(chunk)\n",
    "    result = evaluate(\n",
    "        dataset=chunk, \n",
    "        metrics=[\n",
    "            context_precision,\n",
    "            context_recall,\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "        ]\n",
    "    )\n",
    "    results.append(result.to_pandas())\n",
    "    time.sleep(delay_between_requests)  # Implement delay as calculated\n",
    "# combine results from all chunks\n",
    "final_results = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.736837</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.208712</td>\n",
       "      <td>0.924361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.343289</td>\n",
       "      <td>0.464802</td>\n",
       "      <td>0.367836</td>\n",
       "      <td>0.152510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      context_precision  context_recall  faithfulness  answer_relevancy\n",
       "mean           0.736837        0.602273      0.208712          0.924361\n",
       "std            0.343289        0.464802      0.367836          0.152510\n",
       "min            0.000000        0.000000      0.000000          0.000000\n",
       "max            1.000000        1.000000      1.000000          1.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results.iloc[:,-4:].agg(['mean','std','min','max'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
